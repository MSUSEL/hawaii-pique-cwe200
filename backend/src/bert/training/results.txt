============================================================
      FINAL SUMMARY     
============================================================


==================================================
Model: sentbert  -  Category: variables
==================================================
Final Evaluation Results:
Precision: 0.9383112172197954
Recall:    0.9386503067484663
F1 Score:  0.9384716458951132
Accuracy:  0.9386503067484663
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.96      0.96      0.96       677
    Sensitive       0.82      0.81      0.82       138

     accuracy                           0.94       815
    macro avg       0.89      0.89      0.89       815
 weighted avg       0.94      0.94      0.94       815

Confusion Matrix:
[[653  24]
 [ 26 112]]


==================================================
Model: sentbert  -  Category: strings
==================================================
Final Evaluation Results:
Precision: 0.9566697798084516
Recall:    0.9548254620123203
F1 Score:  0.9556076259413209
Accuracy:  0.9548254620123203
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.98      0.97      0.97       438
    Sensitive       0.75      0.82      0.78        49

     accuracy                           0.95       487
    macro avg       0.87      0.89      0.88       487
 weighted avg       0.96      0.95      0.96       487

Confusion Matrix:
[[425  13]
 [  9  40]]


==================================================
Model: sentbert  -  Category: comments
==================================================
Final Evaluation Results:
Precision: 0.9776355641285726
Recall:    0.9778156996587031
F1 Score:  0.9776809133590895
Accuracy:  0.9778156996587031
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.98      0.99      0.99       486
    Sensitive       0.95      0.92      0.93       100

     accuracy                           0.98       586
    macro avg       0.97      0.95      0.96       586
 weighted avg       0.98      0.98      0.98       586

Confusion Matrix:
[[481   5]
 [  8  92]]


==================================================
Model: sentbert  -  Category: sinks
==================================================
Final Evaluation Results:
Precision: 0.976843085230182
Recall:    0.9774193548387097
F1 Score:  0.976277204599939
Accuracy:  0.9774193548387097
------------------------------------------------
               precision    recall  f1-score   support

          N/A       0.99      0.99      0.99       839
     I/O Sink       0.50      0.17      0.25         6
   Print Sink       0.97      0.97      0.97        37
 Network Sink       0.64      0.78      0.70        18
     Log Sink       0.85      0.85      0.85        20
Database Sink       1.00      0.50      0.67         2
   Email Sink       1.00      1.00      1.00         1
     IPC Sink       1.00      1.00      1.00         7

     accuracy                           0.98       930
    macro avg       0.87      0.78      0.80       930
 weighted avg       0.98      0.98      0.98       930

Confusion Matrix:
[[832   1   0   3   3   0   0   0]
 [  3   1   0   2   0   0   0   0]
 [  0   0  36   1   0   0   0   0]
 [  3   0   1  14   0   0   0   0]
 [  2   0   0   1  17   0   0   0]
 [  0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   7]]


==================================================
Model: t5  -  Category: variables
==================================================
Final Evaluation Results:
Precision: 0.9263170629707317
Recall:    0.9276073619631902
F1 Score:  0.9268516180110429
Accuracy:  0.9276073619631902
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.95      0.96      0.96       677
    Sensitive       0.80      0.76      0.78       138

     accuracy                           0.93       815
    macro avg       0.88      0.86      0.87       815
 weighted avg       0.93      0.93      0.93       815

Confusion Matrix:
[[651  26]
 [ 33 105]]


==================================================
Model: t5  -  Category: strings
==================================================
Final Evaluation Results:
Precision: 0.9683092622962116
Recall:    0.9691991786447639
F1 Score:  0.9677984480906542
Accuracy:  0.9691991786447639
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.97      0.99      0.98       438
    Sensitive       0.93      0.76      0.83        49

     accuracy                           0.97       487
    macro avg       0.95      0.87      0.91       487
 weighted avg       0.97      0.97      0.97       487

Confusion Matrix:
[[435   3]
 [ 12  37]]


==================================================
Model: t5  -  Category: comments
==================================================
Final Evaluation Results:
Precision: 0.984583651771038
Recall:    0.984641638225256
F1 Score:  0.9844840359510537
Accuracy:  0.984641638225256
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.99      1.00      0.99       486
    Sensitive       0.98      0.93      0.95       100

     accuracy                           0.98       586
    macro avg       0.98      0.96      0.97       586
 weighted avg       0.98      0.98      0.98       586

Confusion Matrix:
[[484   2]
 [  7  93]]


==================================================
Model: t5  -  Category: sinks
==================================================
Final Evaluation Results:
Precision: 0.9696188255452894
Recall:    0.975268817204301
F1 Score:  0.9721456214665043
Accuracy:  0.975268817204301
------------------------------------------------
               precision    recall  f1-score   support

          N/A       0.99      0.99      0.99       839
     I/O Sink       0.00      0.00      0.00         6
   Print Sink       0.95      1.00      0.97        37
 Network Sink       0.60      0.67      0.63        18
     Log Sink       0.89      0.80      0.84        20
Database Sink       1.00      0.50      0.67         2
   Email Sink       1.00      1.00      1.00         1
     IPC Sink       1.00      1.00      1.00         7

     accuracy                           0.98       930
    macro avg       0.80      0.74      0.76       930
 weighted avg       0.97      0.98      0.97       930

Confusion Matrix:
[[833   0   0   4   2   0   0   0]
 [  4   0   0   2   0   0   0   0]
 [  0   0  37   0   0   0   0   0]
 [  4   0   2  12   0   0   0   0]
 [  3   0   0   1  16   0   0   0]
 [  0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   7]]


==================================================
Model: codet5  -  Category: variables
==================================================
Final Evaluation Results:
Precision: 0.9282495360458728
Recall:    0.9300613496932515
F1 Score:  0.9258639734959737
Accuracy:  0.9300613496932515
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.94      0.98      0.96       677
    Sensitive       0.89      0.67      0.76       138

     accuracy                           0.93       815
    macro avg       0.91      0.83      0.86       815
 weighted avg       0.93      0.93      0.93       815

Confusion Matrix:
[[666  11]
 [ 46  92]]


==================================================
Model: codet5  -  Category: strings
==================================================
Final Evaluation Results:
Precision: 0.959630360647089
Recall:    0.9609856262833676
F1 Score:  0.9600475632779636
Accuracy:  0.9609856262833676
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.97      0.98      0.98       438
    Sensitive       0.84      0.76      0.80        49

     accuracy                           0.96       487
    macro avg       0.91      0.87      0.89       487
 weighted avg       0.96      0.96      0.96       487

Confusion Matrix:
[[431   7]
 [ 12  37]]


==================================================
Model: codet5  -  Category: comments
==================================================
Final Evaluation Results:
Precision: 0.9982970194336014
Recall:    0.9982935153583617
F1 Score:  0.9982901046276459
Accuracy:  0.9982935153583617
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       1.00      1.00      1.00       486
    Sensitive       1.00      0.99      0.99       100

     accuracy                           1.00       586
    macro avg       1.00      0.99      1.00       586
 weighted avg       1.00      1.00      1.00       586

Confusion Matrix:
[[486   0]
 [  1  99]]


==================================================
Model: codet5  -  Category: sinks
==================================================
Final Evaluation Results:
Precision: 0.9730338923780113
Recall:    0.9731182795698925
F1 Score:  0.9726433961247206
Accuracy:  0.9731182795698925
------------------------------------------------
               precision    recall  f1-score   support

          N/A       0.99      0.99      0.99       839
     I/O Sink       0.75      0.50      0.60         6
   Print Sink       0.97      1.00      0.99        37
 Network Sink       0.65      0.72      0.68        18
     Log Sink       0.83      0.75      0.79        20
Database Sink       1.00      0.50      0.67         2
   Email Sink       1.00      1.00      1.00         1
     IPC Sink       0.86      0.86      0.86         7

     accuracy                           0.97       930
    macro avg       0.88      0.79      0.82       930
 weighted avg       0.97      0.97      0.97       930

Confusion Matrix:
[[829   1   0   5   3   0   0   1]
 [  3   3   0   0   0   0   0   0]
 [  0   0  37   0   0   0   0   0]
 [  4   0   1  13   0   0   0   0]
 [  4   0   0   1  15   0   0   0]
 [  0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0   1   0]
 [  1   0   0   0   0   0   0   6]]


==================================================
Model: codebert  -  Category: variables
==================================================
Final Evaluation Results:
Precision: 0.9222623076878005
Recall:    0.9251533742331288
F1 Score:  0.9226430103999212
Accuracy:  0.9251533742331288
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.94      0.97      0.96       677
    Sensitive       0.83      0.70      0.76       138

     accuracy                           0.93       815
    macro avg       0.89      0.84      0.86       815
 weighted avg       0.92      0.93      0.92       815

Confusion Matrix:
[[657  20]
 [ 41  97]]


==================================================
Model: codebert  -  Category: strings
==================================================
Final Evaluation Results:
Precision: 0.964497228507846
Recall:    0.9650924024640657
F1 Score:  0.9626782278498556
Accuracy:  0.9650924024640657
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.97      1.00      0.98       438
    Sensitive       0.94      0.69      0.80        49

     accuracy                           0.97       487
    macro avg       0.96      0.84      0.89       487
 weighted avg       0.96      0.97      0.96       487

Confusion Matrix:
[[436   2]
 [ 15  34]]


==================================================
Model: codebert  -  Category: comments
==================================================
Final Evaluation Results:
Precision: 0.9931602165848155
Recall:    0.9931740614334471
F1 Score:  0.9931465951467214
Accuracy:  0.9931740614334471
------------------------------------------------
               precision    recall  f1-score   support

Non-sensitive       0.99      1.00      1.00       486
    Sensitive       0.99      0.97      0.98       100

     accuracy                           0.99       586
    macro avg       0.99      0.98      0.99       586
 weighted avg       0.99      0.99      0.99       586

Confusion Matrix:
[[485   1]
 [  3  97]]


==================================================
Model: codebert  -  Category: sinks
==================================================
Final Evaluation Results:
Precision: 0.9677404292299702
Recall:    0.9688172043010753
F1 Score:  0.965898616061659
Accuracy:  0.9688172043010753
------------------------------------------------
               precision    recall  f1-score   support

          N/A       0.98      0.99      0.99       839
     I/O Sink       1.00      0.17      0.29         6
   Print Sink       0.95      1.00      0.97        37
 Network Sink       0.67      0.56      0.61        18
     Log Sink       0.69      0.90      0.78        20
Database Sink       0.00      0.00      0.00         2
   Email Sink       1.00      1.00      1.00         1
     IPC Sink       1.00      0.86      0.92         7

     accuracy                           0.97       930
    macro avg       0.79      0.68      0.69       930
 weighted avg       0.97      0.97      0.97       930

Confusion Matrix:
[[828   0   0   3   8   0   0   0]
 [  5   1   0   0   0   0   0   0]
 [  0   0  37   0   0   0   0   0]
 [  6   0   2  10   0   0   0   0]
 [  1   0   0   1  18   0   0   0]
 [  1   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0]
 [  1   0   0   0   0   0   0   6]]

